{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¦¬ì‚¬ì´ì¦ˆ ë° ë³µì‚¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ì„¤ì •\n",
    "# ==============================================================================\n",
    "# CSV íŒŒì¼ ê²½ë¡œ\n",
    "CSV_PATH = '/content/drive/MyDrive/REM_project/github/dataset/split_data/master_dataset_verified.csv'\n",
    "\n",
    "# ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (êµ¬ê¸€ ë“œë¼ì´ë¸Œ)\n",
    "DRIVE_IMG_ROOT = '/content/drive/MyDrive/mimic_cxr_data/raw'\n",
    "\n",
    "# ì €ì¥í•  ë¡œì»¬ ê²½ë¡œ (í•™ìŠµ ì½”ë“œì™€ ê²½ë¡œë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì´ë¦„ì€ ìœ ì§€í•©ë‹ˆë‹¤)\n",
    "LOCAL_SAVE_DIR = '/content/train_images'\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. í…ŒìŠ¤íŠ¸ ì…‹ ì„ ë³„ (í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ì‹œë“œë¡œ ë¶„ë¦¬)\n",
    "# ==============================================================================\n",
    "print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ ë° í…ŒìŠ¤íŠ¸ ì…‹ ë¶„ë¦¬ ì¤‘...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# â˜…í•µì‹¬â˜…: í•™ìŠµ ë•Œì™€ ë˜‘ê°™ì€ random_state=42ë¥¼ ì¨ì•¼ ì •í™•íˆ í…ŒìŠ¤íŠ¸ ì…‹ë§Œ ê³¨ë¼ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "subject_ids = df['subject_id'].unique()\n",
    "train_ids, temp_ids = train_test_split(subject_ids, test_size=0.2, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë§Œ í•„í„°ë§\n",
    "test_df = df[df['subject_id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… ì „ì²´ ë°ì´í„°: {len(df)}ê°œ\")\n",
    "print(f\"ğŸ¯ ê°€ì ¸ì˜¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê°œ (ì „ì²´ì˜ ì•½ 10%)\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. ì´ë¯¸ì§€ ë³µì‚¬ ë° ë¦¬ì‚¬ì´ì¦ˆ í•¨ìˆ˜\n",
    "# ==============================================================================\n",
    "os.makedirs(LOCAL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def process_and_save_test_image(row_path):\n",
    "    try:\n",
    "        # 1. ì›ë³¸ ê²½ë¡œ\n",
    "        full_src_path = os.path.join(DRIVE_IMG_ROOT, str(row_path))\n",
    "\n",
    "        # 2. ì €ì¥ ê²½ë¡œ\n",
    "        filename = os.path.basename(str(row_path))\n",
    "        filename = os.path.splitext(filename)[0] + \".jpg\"\n",
    "        full_dst_path = os.path.join(LOCAL_SAVE_DIR, filename)\n",
    "\n",
    "        # 3. ì´ë¯¸ ìˆìœ¼ë©´ íŒ¨ìŠ¤\n",
    "        if os.path.exists(full_dst_path):\n",
    "            return True\n",
    "\n",
    "        # 4. ë¦¬ì‚¬ì´ì¦ˆ ë° ì €ì¥\n",
    "        with Image.open(full_src_path) as img:\n",
    "            img = img.convert('RGB')\n",
    "            img = img.resize(IMG_SIZE, Image.LANCZOS)\n",
    "            img.save(full_dst_path, \"JPEG\", quality=85)\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ ì…‹ë§Œ ë³‘ë ¬ ì²˜ë¦¬)\n",
    "# ==============================================================================\n",
    "paths = test_df['path'].tolist()\n",
    "\n",
    "print(f\"ğŸš€ í…ŒìŠ¤íŠ¸ ì…‹ ì´ë¯¸ì§€ {len(paths)}ì¥ì„ ë¡œì»¬ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤...\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    results = list(tqdm(executor.map(process_and_save_test_image, paths), total=len(paths), desc=\"Downloading Test Set\"))\n",
    "\n",
    "success_count = sum(results)\n",
    "print(\"-\" * 50)\n",
    "print(f\"âœ… ì‘ì—… ì™„ë£Œ!\")\n",
    "print(f\"   - ì„±ê³µ: {success_count}ì¥ / {len(paths)}ì¥\")\n",
    "print(f\"   - ì €ì¥ ìœ„ì¹˜: {LOCAL_SAVE_DIR}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "# 1. í•µì‹¬ ë¶€í’ˆ: Gated Cross Attention\n",
    "# (ë°”ì´íƒˆì´ ì—‘ìŠ¤ë ˆì´ì˜ 7x7 ê·¸ë¦¬ë“œ ì¤‘ ì–´ë””ê°€ ì¤‘ìš”í•œì§€ ì°¾ì•„ë‚´ëŠ” ì—­í• )\n",
    "class GatedCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model=1024):\n",
    "        super(GatedCrossAttention, self).__init__()\n",
    "\n",
    "        # Q, K, V ë³€í™˜ì¸µ\n",
    "        self.query_proj = nn.Linear(d_model, d_model) # Vital (ì§ˆë¬¸ì)\n",
    "        self.key_proj = nn.Linear(d_model, d_model)   # Image (ë‹µë³€ í›„ë³´)\n",
    "        self.value_proj = nn.Linear(d_model, d_model) # Image (ì‹¤ì œ ì •ë³´)\n",
    "\n",
    "        # â˜… Gate: ë‹¨ìˆœí•œ ìŠ¤ì¹¼ë¼ ê°’ (í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°)\n",
    "        # 0ì—ì„œ ì‹œì‘í•´ì„œ í•™ìŠµì´ ë ìˆ˜ë¡ ì ì  ì—´ë¦¼\n",
    "        self.gate = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "        # í›„ì²˜ë¦¬\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, img_feat, tab_feat):\n",
    "        # img_feat: (Batch, 1024, 7, 7)\n",
    "        # tab_feat: (Batch, 1024)\n",
    "        B, C, H, W = img_feat.shape\n",
    "\n",
    "        # 1. ì°¨ì› ë§ì¶”ê¸°\n",
    "        img_flat = img_feat.view(B, C, -1).permute(0, 2, 1) # (B, 49, 1024)\n",
    "        vital_query = tab_feat.unsqueeze(1)                 # (B, 1, 1024)\n",
    "\n",
    "        # 2. ì–´í…ì…˜ ìŠ¤ì½”ì–´ ê³„ì‚° (ì—¬ê¸°ê°€ ì¦ê±°ë¥¼ ë§Œë“œëŠ” ê³³!)\n",
    "        Q = self.query_proj(vital_query)\n",
    "        K = self.key_proj(img_flat)\n",
    "        V = self.value_proj(img_flat)\n",
    "\n",
    "        # (Batch, 1, 49) -> 49ê°œ êµ¬ì—­ì— ëŒ€í•œ ì ìˆ˜\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (C ** 0.5)\n",
    "        attn_map = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # 3. ì •ë³´ ê°€ì ¸ì˜¤ê¸° (Context Vector)\n",
    "        context = torch.matmul(attn_map, V) # (Batch, 1, 1024)\n",
    "\n",
    "        # 4. Gated Fusion (ìˆ˜ë„ê¼­ì§€ ì—­í• )\n",
    "        # ì›ë˜ ë°”ì´íƒˆ ì •ë³´ + (Gate * ì—‘ìŠ¤ë ˆì´ì—ì„œ ê°€ì ¸ì˜¨ ì •ë³´)\n",
    "        gate_value = torch.sigmoid(self.gate)\n",
    "        fused_feat = vital_query + (gate_value * context)\n",
    "\n",
    "        fused_feat = self.norm(self.out_proj(fused_feat))\n",
    "\n",
    "        # ê²°ê³¼ê°’ê³¼ í•¨ê»˜ 'attn_map(ì¦ê±°)'ì„ ë¦¬í„´í•´ì¤ë‹ˆë‹¤.\n",
    "        return fused_feat.squeeze(1), attn_map.view(B, H, W)\n",
    "\n",
    "# 2. ì „ì²´ ëª¨ë¸ ì¡°ë¦½\n",
    "class DenseNetFusionModel(nn.Module):\n",
    "    def __init__(self, num_tabular_features, num_classes=1):\n",
    "        super(DenseNetFusionModel, self).__init__()\n",
    "\n",
    "        # ì´ë¯¸ì§€ ì¸ì½”ë” (DenseNet121)\n",
    "        # weights='DEFAULT'ëŠ” ìµœì‹  PyTorch ë²„ì „ìš©ì…ë‹ˆë‹¤.\n",
    "        # êµ¬ë²„ì „ì´ë©´ pretrained=Trueë¡œ ë°”ê¾¸ì„¸ìš”.\n",
    "        self.img_enc = models.densenet121(weights='DEFAULT').features\n",
    "\n",
    "        # ë°”ì´íƒˆ ì¸ì½”ë” (MLP)\n",
    "        self.tab_enc = nn.Sequential(\n",
    "            nn.Linear(num_tabular_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1024), # ì´ë¯¸ì§€ ì±„ë„ìˆ˜(1024)ì— ë§ì¶¤\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # â˜… êµì²´ëœ ë¶€ë¶„: DAFT ëŒ€ì‹  Gated Cross Attention ì‚¬ìš©\n",
    "        self.fusion = GatedCrossAttention(d_model=1024)\n",
    "\n",
    "        # ë¶„ë¥˜ê¸°\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x_img, x_tab):\n",
    "        img_feat = self.img_enc(x_img)  # (B, 1024, 7, 7)\n",
    "        tab_feat = self.tab_enc(x_tab)  # (B, 1024)\n",
    "\n",
    "        # Fusion (ì—¬ê¸°ì„œ Attention Mapì´ íŠ€ì–´ë‚˜ì˜µë‹ˆë‹¤)\n",
    "        fused_feat, attn_map = self.fusion(img_feat, tab_feat)\n",
    "\n",
    "        logits = self.classifier(fused_feat)\n",
    "\n",
    "        # í•™ìŠµí•  ë•ŒëŠ” logitsë§Œ í•„ìš”í•˜ì§€ë§Œ, ë‚˜ì¤‘ì— ê·¸ë¦¼ ê·¸ë¦¬ë ¤ê³  attn_mapë„ ê°™ì´ ë±‰ìŠµë‹ˆë‹¤.\n",
    "        return logits, attn_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„°ì…‹ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. ì„¤ì •\n",
    "BASE_DIR = '/content/drive/MyDrive/REM_project/github/dataset/split_data/'\n",
    "DATA_PATH = BASE_DIR + 'master_dataset_verified.csv'\n",
    "IMG_ROOT = '/content/train_images/'\n",
    "\n",
    "# 2. ë°ì´í„° ë¡œë“œ ë° ë¶„í•  (í•™ìŠµ ë•Œì™€ ë™ì¼í•œ Seed=42 í•„ìˆ˜)\n",
    "print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ ë° ë¶„í•  ì¤‘...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "subject_ids = df['subject_id'].unique()\n",
    "\n",
    "train_ids, temp_ids = train_test_split(subject_ids, test_size=0.2, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ë§Œ í•„ìš”\n",
    "test_df = df[df['subject_id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "# 3. ì •ê·œí™”ìš© í†µê³„ëŸ‰ (Train ì…‹ ê¸°ì¤€ê°’ - í•™ìŠµ ë•Œ ì“´ ê°’ê³¼ ë™ì¼í•´ì•¼ í•¨)\n",
    "# ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ì „ì²´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ê·¼ì‚¬ê°’ì„ ì‚¬ìš©í•˜ê±°ë‚˜, í•™ìŠµ ì½”ë“œì˜ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "# í˜„ì¬ ì½”ë“œ (Line 194)\n",
    "TABULAR_COLS = ['gender', 'anchor_age', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'WBC', 'BNP']# (ì›ë˜ëŠ” train_dfì—ì„œ ê³„ì‚°í•´ì•¼ í•˜ì§€ë§Œ, ì‹¤í–‰ í¸ì˜ë¥¼ ìœ„í•´ ì—¬ê¸°ì„  test_df ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ í•˜ë“œì½”ë”© ê°€ëŠ¥)\n",
    "# ì •í™•ë„ë¥¼ ìœ„í•´ Train ì…‹ì„ ì ê¹ ë¶ˆëŸ¬ì™€ì„œ ê³„ì‚°\n",
    "train_subset = df[df['subject_id'].isin(train_ids)]\n",
    "scaler_mean = train_subset[TABULAR_COLS].mean()\n",
    "scaler_std = train_subset[TABULAR_COLS].std().replace(0, 1)\n",
    "\n",
    "# 4. Dataset í´ë˜ìŠ¤ ì •ì˜\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_root, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "        self.target_cols = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion', 'Pneumonia']\n",
    "        self.tabular_cols = TABULAR_COLS\n",
    "        self.mean = scaler_mean\n",
    "        self.std = scaler_std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # ì´ë¯¸ì§€\n",
    "        original_path = str(row['path'])\n",
    "        filename = os.path.basename(original_path)\n",
    "        filename = os.path.splitext(filename)[0] + \".jpg\"\n",
    "        full_img_path = os.path.join(self.img_root, filename)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(full_img_path).convert('RGB')\n",
    "        except:\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0)) # ì—ëŸ¬ ë°©ì§€ìš© ê²€ì€ìƒ‰ ì´ë¯¸ì§€\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # ë°”ì´íƒˆ ë°ì´í„° (ì •ê·œí™”)\n",
    "        tabular = row[self.tabular_cols].values.astype(np.float32)\n",
    "        tabular = (tabular - self.mean.values.astype(np.float32)) / self.std.values.astype(np.float32)\n",
    "\n",
    "        # ì •ë‹µ ë¼ë²¨\n",
    "        labels = row[self.target_cols].values.astype(np.float32)\n",
    "\n",
    "        return image, torch.tensor(tabular), torch.tensor(labels)\n",
    "\n",
    "# 5. Loader ìƒì„±\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = MultimodalDataset(test_df, IMG_ROOT, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Make TARGET_COLS globally available for other cells\n",
    "TARGET_COLS = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion', 'Pneumonia']\n",
    "\n",
    "print(f\"âœ… test_loader ì¤€ë¹„ ì™„ë£Œ! (ë°ì´í„° ê°œìˆ˜: {len(test_dataset)}ê°œ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í“¨ì „ ëª¨ë¸ê³¼ ì´ë¯¸ì§€ ì˜¨ë¦¬ ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, roc_auc_score # Added roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming BASE_DIR is defined in a previous cell\n",
    "# If not, you might need to define it here or run the cell where it's defined.\n",
    "BASE_DIR = '/content/drive/MyDrive/REM_project/github/dataset/split_data/'\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Image-Only ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (ë¹„êµêµ°)\n",
    "# ---------------------------------------------------------\n",
    "class ImageOnlyDenseNet(nn.Module):\n",
    "    def __init__(self, num_classes=6): # Changed num_classes to 6\n",
    "        super().__init__()\n",
    "        # Fusion ëª¨ë¸ê³¼ ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´ ë˜‘ê°™ì€ DenseNet121 ì‚¬ìš©\n",
    "        self.backbone = models.densenet121(pretrained=False)\n",
    "        num_ftrs = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. í‰ê°€ í•¨ìˆ˜ (Fusion vs Image-Only ìë™ êµ¬ë¶„)\n",
    "# ---------------------------------------------------------\n",
    "def get_all_predictions(model, loader, device, model_type='fusion'):\n",
    "    model.eval()\n",
    "    y_true_list = []\n",
    "    y_scores_list = [] # Store probabilities for all classes\n",
    "    y_preds_list = []  # Store 0 or 1 predictions for all classes\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, tabular, labels in tqdm(loader, desc=f\"Testing {model_type}...\"):\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            # ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ì…ë ¥ ë°©ì‹ ë¶„ê¸° ì²˜ë¦¬\n",
    "            if model_type == 'fusion':\n",
    "                tabular = tabular.to(device).float()\n",
    "                logits, _ = model(images, tabular) # Extract logits from the tuple output\n",
    "            else:\n",
    "                logits = model(images)\n",
    "\n",
    "            probs = torch.sigmoid(logits).cpu().numpy() # Apply sigmoid only to logits\n",
    "            preds = (probs > 0.5).astype(int)            # (batch_size, num_classes)\n",
    "\n",
    "            y_true_list.append(labels.cpu().numpy())\n",
    "            y_scores_list.append(probs)\n",
    "            y_preds_list.append(preds)\n",
    "\n",
    "    return np.concatenate(y_true_list), np.concatenate(y_scores_list), np.concatenate(y_preds_list)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ë©”ì¸ ë¹„êµ ì‹¤í–‰ (Main Execution)\n",
    "# ---------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# (1) ë°ì´í„° ë¡œë” ì¤€ë¹„ (test_loaderê°€ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)\n",
    "# test_loader = ... (ì„ ìƒë‹˜ì˜ test_loader ì‚¬ìš©)\n",
    "\n",
    "# (2) Fusion ëª¨ë¸ ë¡œë“œ\n",
    "fusion_model = DenseNetFusionModel(num_classes=6, num_tabular_features=10).to(device) # Changed tabular_input_dim to 10\n",
    "# ì €ì¥í•´ë‘” Fusion ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "try:\n",
    "    # Corrected path to use BASE_DIR\n",
    "    fusion_model.load_state_dict(torch.load(os.path.join(BASE_DIR, \"best_fusion_model.pth\")))\n",
    "    print(\"âœ… Fusion Model Loaded.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ Fusion Model weights not found. Skipping...\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"âŒ Error loading Fusion Model weights: {e}. Skipping...\")\n",
    "\n",
    "# (3) Image-Only ëª¨ë¸ ë¡œë“œ (ë¹„êµêµ°)\n",
    "image_model = ImageOnlyDenseNet(num_classes=6).to(device) # Changed num_classes to 6\n",
    "# ì €ì¥í•´ë‘” Image-Only ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "try:\n",
    "    # Corrected path to use BASE_DIR\n",
    "    image_model.load_state_dict(torch.load(os.path.join(BASE_DIR, \"best_image_only_model.pth\")))\n",
    "    print(\"âœ… Image-Only Model Loaded.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ Image-Only Model weights not found. (ë¹„êµë¥¼ ìœ„í•´ í•™ìŠµ í›„ ì €ì¥ í•„ìš”)\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"âŒ Error loading Image-Only Model weights: {e}. Skipping...\")\n",
    "\n",
    "# (4) ì¶”ë¡  ì‹¤í–‰\n",
    "print(\"\\n--- Running Inference ---\")\n",
    "# Fusion ì˜ˆì¸¡\n",
    "y_true_all, f_scores_all, f_preds_all = get_all_predictions(fusion_model, test_loader, device, model_type='fusion')\n",
    "# Image-Only ì˜ˆì¸¡\n",
    "_, i_scores_all, i_preds_all = get_all_predictions(image_model, test_loader, device, model_type='image_only')\n",
    "\n",
    "num_classes = y_true_all.shape[1] # Number of diseases\n",
    "\n",
    "# Calculate Macro AUROC\n",
    "f_aucs_macro = []\n",
    "i_aucs_macro = []\n",
    "for i in range(num_classes):\n",
    "    try:\n",
    "        f_aucs_macro.append(roc_auc_score(y_true_all[:, i], f_scores_all[:, i]))\n",
    "    except ValueError:\n",
    "        f_aucs_macro.append(0.5) # Handle cases with only one class present\n",
    "    try:\n",
    "        i_aucs_macro.append(roc_auc_score(y_true_all[:, i], i_scores_all[:, i]))\n",
    "    except ValueError:\n",
    "        i_aucs_macro.append(0.5)\n",
    "\n",
    "f_auc_macro = np.mean(f_aucs_macro)\n",
    "i_auc_macro = np.mean(i_aucs_macro)\n",
    "\n",
    "# Calculate Micro AUROC for plotting and overall summary\n",
    "f_fpr_micro, f_tpr_micro, _ = roc_curve(y_true_all.ravel(), f_scores_all.ravel())\n",
    "f_auc_micro = auc(f_fpr_micro, f_tpr_micro)\n",
    "\n",
    "i_fpr_micro, i_tpr_micro, _ = roc_curve(y_true_all.ravel(), i_scores_all.ravel())\n",
    "i_auc_micro = auc(i_fpr_micro, i_tpr_micro)\n",
    "\n",
    "print(f\"\\nğŸ“Š Result Summary:\")\n",
    "print(f\"Image-Only Macro AUROC: {i_auc_macro:.4f}\")\n",
    "print(f\"Fusion     Macro AUROC: {f_auc_macro:.4f} (Diff: {f_auc_macro - i_auc_macro:+.4f})\")\n",
    "print(f\"\\nImage-Only Micro AUROC: {i_auc_micro:.4f}\")\n",
    "print(f\"Fusion     Micro AUROC: {f_auc_micro:.4f} (Diff: {f_auc_micro - i_auc_micro:+.4f})\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ì‹œê°í™”: ROC Curve ê²¹ì³ ê·¸ë¦¬ê¸° (ë…¼ë¬¸ìš© ê·¸ë¦¼) - Using Micro-Average\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Image-Only ê³¡ì„  (íŒŒì„ )\n",
    "plt.plot(i_fpr_micro, i_tpr_micro, linestyle='--', color='gray', label=f'Image Only (Micro AUC = {i_auc_micro:.3f})')\n",
    "\n",
    "# Fusion ê³¡ì„  (ì‹¤ì„ , ë¹¨ê°„ìƒ‰ ê°•ì¡°)\n",
    "plt.plot(f_fpr_micro, f_tpr_micro, linestyle='-', color='red', linewidth=2, label=f'Ours (Fusion) (Micro AUC = {f_auc_micro:.3f})')\n",
    "\n",
    "# ê¸°ì¤€ì„ \n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle=':', alpha=0.5)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison: Fusion vs Image-Only (Micro-Average)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. í˜¼ë™ í–‰ë ¬ (Confusion Matrix) ë¹„êµ - ì„ íƒ ì‚¬í•­ (Micro-Average)\n",
    "# ---------------------------------------------------------\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Flatten for micro-average confusion matrix and accuracy\n",
    "sns.heatmap(confusion_matrix(y_true_all.flatten(), i_preds_all.flatten()), annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
    "ax[0].set_title(f\"Image-Only (Micro Acc: {accuracy_score(y_true_all.flatten(), i_preds_all.flatten()):.3f})\")\n",
    "ax[0].set_xlabel(\"Predicted\")\n",
    "ax[0].set_ylabel(\"Actual\")\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_true_all.flatten(), f_preds_all.flatten()), annot=True, fmt='d', cmap='Reds', ax=ax[1])\n",
    "ax[1].set_title(f\"Fusion (Micro Acc: {accuracy_score(y_true_all.flatten(), f_preds_all.flatten()):.3f})\")\n",
    "ax[1].set_xlabel(\"Predicted\")\n",
    "ax[1].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ëŠ” ë…¼ë¬¸ì— ë„£ê¸° ìœ„í•œ í‘œì™€ ê·¸ë˜í”„ë¥¼ ë½‘ëŠ” ì½”ë“œë“¤ì…ë‹ˆë‹¤..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# [Fix] ë³€ìˆ˜ëª… ë§¤í•‘ (ì´ë¦„í‘œ ë‹¬ì•„ì£¼ê¸°)\n",
    "# -----------------------------------------------------------\n",
    "# ì•ì„  ì½”ë“œì—ì„œ ë¡œë“œí•œ ëª¨ë¸ë“¤ì„ ì§„ë‹¨ ì½”ë“œì˜ ì´ë¦„ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "model = fusion_model           # Multimodal ëª¨ë¸\n",
    "model_img_only = image_model   # Image-Only ëª¨ë¸\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ë³€ìˆ˜ëª… ì—°ê²° ì™„ë£Œ!\")\n",
    "print(f\"   - model -> {type(model).__name__}\")\n",
    "print(f\"   - model_img_only -> {type(model_img_only).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. ì„¤ì •\n",
    "# -----------------------------------------------------------------------------\n",
    "# ë¶„ì„í•  6ëŒ€ ì§ˆí™˜ëª… (ìˆœì„œê°€ ë°ì´í„°ì…‹ê³¼ ì¼ì¹˜í•´ì•¼ í•¨)\n",
    "DISEASE_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion', 'Pneumonia']\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. ì§ˆí™˜ë³„ AUROC ê³„ì‚° í•¨ìˆ˜\n",
    "# -----------------------------------------------------------------------------\n",
    "def analyze_per_disease(model_fusion, model_img, loader, device):\n",
    "    print(\"ğŸ” ì§ˆí™˜ë³„ ì„±ëŠ¥ ì •ë°€ ë¶„ì„ ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)\")\n",
    "\n",
    "    # 1. ì˜ˆì¸¡ê°’ ì¶”ì¶œ\n",
    "    y_true, f_scores, _ = get_all_predictions(model_fusion, loader, device, model_type='fusion')\n",
    "    _, i_scores, _ = get_all_predictions(model_img, loader, device, model_type='image_only')\n",
    "\n",
    "    # y_true, f_scoresì˜ shapeì€ (N_samples, 6) ì´ì–´ì•¼ í•¨ (Flatten ëœ ìƒíƒœë©´ Reshape í•„ìš”)\n",
    "    # get_all_predictions í•¨ìˆ˜ê°€ flattenì„ ë°˜í™˜í–ˆë‹¤ë©´ ë‹¤ì‹œ reshape\n",
    "    if f_scores.ndim == 1:\n",
    "        f_scores = f_scores.reshape(-1, 6)\n",
    "        i_scores = i_scores.reshape(-1, 6)\n",
    "        y_true = y_true.reshape(-1, 6)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # 2. ì§ˆí™˜ë³„ ê³„ì‚°\n",
    "    for idx, disease in enumerate(DISEASE_NAMES):\n",
    "        # ì •ë‹µì´ í•˜ë‚˜ë„ ì—†ëŠ” í´ë˜ìŠ¤ ë°©ì§€\n",
    "        if len(np.unique(y_true[:, idx])) < 2:\n",
    "            print(f\"âš ï¸ {disease}: í…ŒìŠ¤íŠ¸ì…‹ì— ì–‘ì„± ìƒ˜í”Œì´ ì—†ì–´ì„œ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            continue\n",
    "\n",
    "        auc_fusion = roc_auc_score(y_true[:, idx], f_scores[:, idx])\n",
    "        auc_img = roc_auc_score(y_true[:, idx], i_scores[:, idx])\n",
    "\n",
    "        diff = auc_fusion - auc_img\n",
    "        status = \"ğŸ”ºìƒìŠ¹\" if diff > 0 else \"ğŸ”»í•˜ë½\"\n",
    "\n",
    "        results.append({\n",
    "            \"Disease\": disease,\n",
    "            \"Image-Only\": auc_img,\n",
    "            \"Fusion (Ours)\": auc_fusion,\n",
    "            \"Diff\": diff,\n",
    "            \"Status\": status\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. ì‹¤í–‰ ë° ì‹œê°í™”\n",
    "# -----------------------------------------------------------------------------\n",
    "# ëª¨ë¸ê³¼ ë¡œë”ê°€ ë©”ëª¨ë¦¬ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "df_result = analyze_per_disease(fusion_model, image_model, test_loader, device)\n",
    "\n",
    "# 4. í‘œ ì¶œë ¥ (ì˜ˆì˜ê²Œ)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š [ì§ˆí™˜ë³„ ì„±ëŠ¥ ìƒì„¸ ë¹„êµí‘œ]\")\n",
    "print(\"=\"*60)\n",
    "# ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ í‘œì‹œ\n",
    "print(df_result.round(4).to_string(index=False))\n",
    "\n",
    "# 5. ê·¸ë˜í”„ ì‹œê°í™” (ìƒìŠ¹/í•˜ë½í­)\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red' if x > 0 else 'blue' for x in df_result['Diff']]\n",
    "sns.barplot(x='Diff', y='Disease', data=df_result, palette=colors)\n",
    "\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "plt.title(f\"Performance Gain by Fusion (Total Mean Diff: {df_result['Diff'].mean():.4f})\")\n",
    "plt.xlabel(\"AUROC Improvement (Fusion - ImageOnly)\")\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# ìˆ˜ì¹˜ í‘œì‹œ\n",
    "for i, v in enumerate(df_result['Diff']):\n",
    "    plt.text(v, i, f\"{v:+.4f}\", va='center', fontweight='bold',\n",
    "             color='red' if v > 0 else 'blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# 1. ì„¤ì • (ì´ì „ ì½”ë“œ ì‹¤í–‰ í›„ ë³€ìˆ˜ë“¤ì´ ë©”ëª¨ë¦¬ì— ìˆë‹¤ê³  ê°€ì •)\n",
    "# =============================================================================\n",
    "# ë§Œì•½ ì´ì „ ì½”ë“œê°€ êº¼ì¡Œë‹¤ë©´, 03ë²ˆ ì½”ë“œì˜ ëª¨ë¸ ë¡œë“œ ë¶€ë¶„ê¹Œì§€ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\n",
    "print(\"ğŸ§ª ë°”ì´íƒˆ ì˜ì¡´ë„(Permutation Importance) í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "\n",
    "def get_auc_per_disease(labels, preds):\n",
    "    aucs = []\n",
    "    for i in range(len(TARGET_COLS)):\n",
    "        try:\n",
    "            score = roc_auc_score(labels[:, i], preds[:, i])\n",
    "        except:\n",
    "            score = 0.5\n",
    "        aucs.append(score)\n",
    "    return np.mean(aucs), aucs\n",
    "\n",
    "# =============================================================================\n",
    "# 2. ì •ìƒ ë°ì´í„° ì¶”ë¡  (Baseline)\n",
    "# =============================================================================\n",
    "# ì´ë¯¸ 03ë²ˆ ì½”ë“œì—ì„œ preds_multië¥¼ êµ¬í–ˆë‹¤ë©´ ìƒëµ ê°€ëŠ¥í•˜ì§€ë§Œ, í™•ì‹¤íˆ í•˜ê¸° ìœ„í•´ ë‹¤ì‹œ í•¨\n",
    "model.eval() # Changed model_multi to model\n",
    "all_preds_original = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, tabs, lbls in tqdm(test_loader, desc=\"Original Inference\"):\n",
    "        imgs, tabs = imgs.to(device), tabs.to(device)\n",
    "        outputs = model(imgs, tabs)\n",
    "        logits, _ = outputs # Extract logits from the tuple output\n",
    "        all_preds_original.append(torch.sigmoid(logits).cpu().numpy())\n",
    "        all_labels.append(lbls.numpy())\n",
    "\n",
    "preds_original = np.vstack(all_preds_original)\n",
    "labels_np = np.vstack(all_labels)\n",
    "mean_auc_orig, aucs_orig = get_auc_per_disease(labels_np, preds_original)\n",
    "\n",
    "print(f\"\\nâœ… ì›ë³¸ í‰ê·  AUROC: {mean_auc_orig:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. ë°”ì´íƒˆ ì…”í”Œë§ ì¶”ë¡  (Shuffled Inference)\n",
    "# =============================================================================\n",
    "# ë°ì´í„°ë¡œë”ë¥¼ ë‹¤ì‹œ ëŒë©´ì„œ, ì´ë²ˆì—” tabular ë°ì´í„°ë§Œ ë°°ì¹˜ ë‚´ì—ì„œ ì„ì–´ë²„ë¦¼\n",
    "all_preds_shuffled = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, tabs, lbls in tqdm(test_loader, desc=\"Shuffled Vitals\"):\n",
    "        imgs, tabs = imgs.to(device), tabs.to(device)\n",
    "\n",
    "        # â˜… í•µì‹¬: ë°”ì´íƒˆ ë°ì´í„°(tabs)ë¥¼ ëœë¤í•˜ê²Œ ì„ì–´ë²„ë¦¼ (Batch ë‚´ ì…”í”Œ)\n",
    "        # í™˜ì Aì˜ ì‚¬ì§„ì— í™˜ì Bì˜ ë°”ì´íƒˆì´ ë“¤ì–´ê°€ëŠ” ìƒí™©ì„ ë§Œë“¦\n",
    "        shuffled_idx = torch.randperm(tabs.size(0))\n",
    "        tabs_shuffled = tabs[shuffled_idx]\n",
    "\n",
    "        outputs = model(imgs, tabs_shuffled)\n",
    "        logits, _ = outputs # Extract logits from the tuple output\n",
    "        all_preds_shuffled.append(torch.sigmoid(logits).cpu().numpy())\n",
    "\n",
    "preds_shuffled = np.vstack(all_preds_shuffled)\n",
    "mean_auc_shuf, aucs_shuf = get_auc_per_disease(labels_np, preds_shuffled)\n",
    "\n",
    "print(f\"âŒ ì…”í”Œ í‰ê·  AUROC: {mean_auc_shuf:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. ê²°ê³¼ ë¹„êµ ë° ì‹œê°í™”\n",
    "# =============================================================================\n",
    "drop = mean_auc_orig - mean_auc_shuf\n",
    "print(f\"\\nğŸ“‰ ì„±ëŠ¥ í•˜ë½í­ (Importance): {drop:.4f}\")\n",
    "\n",
    "if drop < 0.005:\n",
    "    print(\"ğŸš¨ ê²°ë¡ : ëª¨ë¸ì´ ë°”ì´íƒˆì„ ê±°ì˜ ë¬´ì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤! (ì ìˆ˜ ì°¨ì´ ì—†ìŒ)\")\n",
    "else:\n",
    "    print(\"ğŸŸ¢ ê²°ë¡ : ëª¨ë¸ì´ ë°”ì´íƒˆ ì •ë³´ë¥¼ ìœ ì˜ë¯¸í•˜ê²Œ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì§ˆí™˜ë³„ í•˜ë½í­ ì‹œê°í™”\n",
    "drops = [a - b for a, b in zip(aucs_orig, aucs_shuf)]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(TARGET_COLS, drops, color='#ff6b6b', edgecolor='black')\n",
    "plt.title(\"Performance Drop when Vitals are Randomized\", fontsize=14)\n",
    "plt.ylabel(\"AUROC Drop\")\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(drops):\n",
    "    plt.text(i, v, f\"{v:.4f}\", ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì„¤ì •\n",
    "# ---------------------------------------------------------\n",
    "DISEASE_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion', 'Pneumonia']\n",
    "THRESHOLD = 0.5 # 0.5 ì´ìƒì´ë©´ ì–‘ì„±ìœ¼ë¡œ íŒë‹¨\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. ìƒì„¸ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜\n",
    "# ---------------------------------------------------------\n",
    "def get_detailed_metrics(y_true, y_scores):\n",
    "    # í™•ë¥  -> 0/1 ì˜ˆì¸¡ê°’ ë³€í™˜\n",
    "    y_pred = (y_scores > THRESHOLD).astype(int)\n",
    "\n",
    "    # í˜¼ë™ í–‰ë ¬ (TN, FP, FN, TP)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "\n",
    "    # ë¯¼ê°ë„ (Recall, Sensitivity): í™˜ìë¥¼ í™˜ìë¼ê³  ë§ì¶˜ ë¹„ìœ¨\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    # íŠ¹ì´ë„ (Specificity): ì •ìƒì„ ì •ìƒì´ë¼ê³  ë§ì¶˜ ë¹„ìœ¨\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    # ì •ë°€ë„ (Precision)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "    return sensitivity, specificity, precision, tp, fn\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ë¶„ì„ ì‹¤í–‰\n",
    "# ---------------------------------------------------------\n",
    "# ì˜ˆì¸¡ê°’ ê°€ì ¸ì˜¤ê¸° (ì´ë¯¸ ë©”ëª¨ë¦¬ì— ìˆë‹¤ë©´ ìƒëµ ê°€ëŠ¥)\n",
    "print(\"running analysis...\")\n",
    "y_true, f_scores, _ = get_all_predictions(fusion_model, test_loader, device, model_type='fusion')\n",
    "_, i_scores, _ = get_all_predictions(image_model, test_loader, device, model_type='image_only')\n",
    "\n",
    "# Shape ë§ì¶”ê¸°\n",
    "if f_scores.ndim == 1:\n",
    "    f_scores = f_scores.reshape(-1, 6)\n",
    "    i_scores = i_scores.reshape(-1, 6)\n",
    "    y_true = y_true.reshape(-1, 6)\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, disease in enumerate(DISEASE_NAMES):\n",
    "    # Image-Only ì§€í‘œ\n",
    "    i_sens, i_spec, i_prec, i_tp, i_fn = get_detailed_metrics(y_true[:, idx], i_scores[:, idx])\n",
    "\n",
    "    # Fusion ì§€í‘œ\n",
    "    f_sens, f_spec, f_prec, f_tp, f_fn = get_detailed_metrics(y_true[:, idx], f_scores[:, idx])\n",
    "\n",
    "    # ë³€í™”ëŸ‰ (Fusion - ImageOnly)\n",
    "    diff_sens = f_sens - i_sens\n",
    "\n",
    "    results.append({\n",
    "        \"Disease\": disease,\n",
    "        \"Img_Sens\": f\"{i_sens:.4f}\",\n",
    "        \"Fus_Sens\": f\"{f_sens:.4f}\",\n",
    "        \"Diff_Sens\": f\"{diff_sens:+.4f}\", # ë¯¼ê°ë„ ë³€í™” (ì¤‘ìš”!)\n",
    "        \"Img_Missed(FN)\": i_fn,\n",
    "        \"Fus_Missed(FN)\": f_fn, # ë†“ì¹œ í™˜ì ìˆ˜ (ì¤„ì–´ë“¤ë©´ ì¢‹ìŒ)\n",
    "        \"Gain(TP)\": f_tp - i_tp # ì¶”ê°€ë¡œ ì°¾ì•„ë‚¸ í™˜ì ìˆ˜\n",
    "    })\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. ê²°ê³¼ ì¶œë ¥\n",
    "# ---------------------------------------------------------\n",
    "df_analysis = pd.DataFrame(results)\n",
    "print(\"\\nğŸ¥ [ì§ˆí™˜ë³„ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸]\")\n",
    "print(\"Focus: ë¯¼ê°ë„(Sensitivity)ê°€ ì˜¤ë¥¸ ì§ˆë³‘ì„ ì°¾ìœ¼ì„¸ìš”!\")\n",
    "print(\"-\" * 80)\n",
    "print(df_analysis.to_string(index=False))\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "íˆíŠ¸ë§µ ì‹œê°í™”..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# í•¨ìˆ˜ ì •ì˜: Image Only(CNN Feature) vs Fusion(Attention) ë¹„êµ\n",
    "# -------------------------------------------------------------------------\n",
    "def compare_visual_evidence(model, dataloader, target_disease='Pneumonia', num_samples=3):\n",
    "\n",
    "    # í´ë˜ìŠ¤ ì´ë¦„ (ì„ ìƒë‹˜ ë°ì´í„°ì…‹ ìˆœì„œì— ë§ê²Œ ìˆ˜ì • í•„ìš”)\n",
    "    class_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion', 'Pneumonia']\n",
    "    target_idx = class_names.index(target_disease)\n",
    "\n",
    "    print(f\"ğŸ” [{target_disease}] ë¹„êµ ë¶„ì„ ì‹œì‘...\")\n",
    "    model.eval()\n",
    "\n",
    "    found = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, vitals, labels in dataloader:\n",
    "            imgs, vitals, labels = imgs.to(device), vitals.to(device), labels.to(device)\n",
    "\n",
    "            # 1. ëª¨ë¸ì—ì„œ íŠ¹ì§•ê³¼ ì–´í…ì…˜ ë§µ ì¶”ì¶œ\n",
    "            # (DenseNetFusionModelì˜ forwardë¥¼ ìˆ˜ì •í–ˆìœ¼ë¯€ë¡œ img_feat ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í˜¸ì¶œ)\n",
    "\n",
    "            # ì´ë¯¸ì§€ ì¸ì½”ë”ì˜ ìˆœìˆ˜ íŠ¹ì§• (Image Only ì‹œì„  ëŒ€ìš©)\n",
    "            img_feat = model.img_enc(imgs)  # (B, 1024, 7, 7)\n",
    "\n",
    "            # Fusion ëª¨ë¸ì˜ ì˜ˆì¸¡ ë° ì–´í…ì…˜ ë§µ\n",
    "            logits, attn_maps = model(imgs, vitals)\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            for i in range(imgs.size(0)):\n",
    "                # ì¡°ê±´: ì‹¤ì œ í™˜ìì´ê³ (Target=1), ëª¨ë¸ì´ ê°•í•˜ê²Œ ì˜ˆì¸¡(Prob>0.7)í•œ ê²½ìš°\n",
    "                if labels[i, target_idx] == 1 and probs[i, target_idx] > 0.7:\n",
    "\n",
    "                    # --- A. ì›ë³¸ ì´ë¯¸ì§€ ë³µì› ---\n",
    "                    inv_img = imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "                    inv_img = (inv_img - inv_img.min()) / (inv_img.max() - inv_img.min())\n",
    "                    inv_img_uint8 = np.uint8(255 * inv_img)\n",
    "\n",
    "                    # --- B. Image Only ì‹œì„  (CNN Feature Map í‰ê· ) ---\n",
    "                    # 1024ê°œ ì±„ë„ì˜ í™œì„±í™”ë¥¼ í‰ê· ë‚´ì–´ \"CNNì´ ì¤‘ìš”í•˜ê²Œ ë³¸ ê³³\"ì„ ì¶”ì •\n",
    "                    cam_img = img_feat[i].mean(dim=0).cpu().numpy() # (7, 7)\n",
    "                    cam_img = cv2.resize(cam_img, (224, 224))\n",
    "                    cam_img = (cam_img - cam_img.min()) / (cam_img.max() - cam_img.min())\n",
    "                    heatmap_img = cv2.applyColorMap(np.uint8(255 * cam_img), cv2.COLORMAP_VIRIDIS)\n",
    "                    heatmap_img = cv2.cvtColor(heatmap_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # --- C. Fusion ì‹œì„  (Gated Cross Attention Map) ---\n",
    "                    # ë°”ì´íƒˆ ì •ë³´ê°€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•œ \"ì§„ì§œ ì¦ê±°\"\n",
    "                    att = attn_maps[i].cpu().numpy() # (7, 7)\n",
    "                    att = cv2.resize(att, (224, 224))\n",
    "                    att = (att - att.min()) / (att.max() - att.min()) # ì •ê·œí™”\n",
    "                    heatmap_fus = cv2.applyColorMap(np.uint8(255 * att), cv2.COLORMAP_JET) # ë¶‰ì€ìƒ‰ ê°•ì¡°\n",
    "                    heatmap_fus = cv2.cvtColor(heatmap_fus, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # --- D. ì˜¤ë²„ë ˆì´ ìƒì„± ---\n",
    "                    overlay_img = cv2.addWeighted(inv_img_uint8, 0.6, heatmap_img, 0.4, 0)\n",
    "                    overlay_fus = cv2.addWeighted(inv_img_uint8, 0.6, heatmap_fus, 0.4, 0)\n",
    "\n",
    "                    # --- ì‹œê°í™” ---\n",
    "                    plt.figure(figsize=(15, 5))\n",
    "\n",
    "                    # 1. ì›ë³¸\n",
    "                    plt.subplot(1, 4, 1)\n",
    "                    plt.title(f\"Original X-ray\\n({target_disease})\")\n",
    "                    plt.imshow(inv_img)\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    # 2. Image Only (CNN ì‹œì„ )\n",
    "                    plt.subplot(1, 4, 2)\n",
    "                    plt.title(\"Image Only Focus\\n(CNN Features)\")\n",
    "                    plt.imshow(overlay_img)\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    # 3. Fusion (Vital Guide)\n",
    "                    plt.subplot(1, 4, 3)\n",
    "                    plt.title(\"Fusion Focus\\n(Vital Guided)\")\n",
    "                    plt.imshow(overlay_fus) # ë¶‰ì€ìƒ‰ì´ ì§‘ì¤‘ëœ ê³³\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    # 4. ì°¨ì´ ê°•ì¡° (Fusion - Image)\n",
    "                    # í“¨ì „ì´ ë” ë³´ê²Œ ëœ ê³³ì„ í‘œì‹œ\n",
    "                    diff = att - cam_img\n",
    "                    diff = np.maximum(diff, 0) # ì–‘ìˆ˜ë§Œ (í“¨ì „ ë•ë¶„ì— ë” ë³´ê²Œ ëœ ê³³)\n",
    "                    diff = (diff - diff.min()) / (diff.max() - diff.min() + 1e-8)\n",
    "                    heatmap_diff = cv2.applyColorMap(np.uint8(255 * diff), cv2.COLORMAP_HOT)\n",
    "                    heatmap_diff = cv2.cvtColor(heatmap_diff, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    plt.subplot(1, 4, 4)\n",
    "                    plt.title(\"Vital Gain\\n(Added Attention)\")\n",
    "                    plt.imshow(heatmap_diff)\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "                    found += 1\n",
    "                    if found >= num_samples:\n",
    "                        print(\"âœ… ì‹œê°í™” ì™„ë£Œ.\")\n",
    "                        return\n",
    "\n",
    "# ì‹¤í–‰ (test_loader ì‚¬ìš©)\n",
    "compare_visual_evidence(model, test_loader, target_disease='Pneumonia', num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_original_resolution_heatmap(model, loader, dataframe, target_disease='Pneumonia', save_dir='./', num_samples=1):\n",
    "    # 1. ì„¤ì •\n",
    "    class_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion', 'Pneumonia']\n",
    "    target_idx = class_names.index(target_disease)\n",
    "\n",
    "    # ì›ë³¸ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ (ì„¤ì •ëœ ê²½ë¡œ í™œìš©)\n",
    "    # 03ë²ˆ íŒŒì¼ ìƒë‹¨ì— ì •ì˜ëœ DRIVE_IMG_ROOT ì‚¬ìš©\n",
    "    img_root_path = '/content/drive/MyDrive/mimic_cxr_data/raw'\n",
    "\n",
    "    model.eval()\n",
    "    print(f\"qh ğŸ“¸ [{target_disease}] ê³ í™”ì§ˆ ì›ë³¸ ê²½ë¡œ ë§¤ì¹­ ë° íˆíŠ¸ë§µ ìƒì„± ì¤‘...\")\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„°ë¥¼ ìˆœíšŒí•˜ë©° ì°¾ê¸°\n",
    "    global_idx = 0\n",
    "    found_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, vitals, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            vitals = vitals.to(device)\n",
    "\n",
    "            # Fusion ëª¨ë¸ ì˜ˆì¸¡ ë° ì–´í…ì…˜ ë§µ ì¶”ì¶œ\n",
    "            logits, attn_maps = model(imgs, vitals) # Fusion ëª¨ë¸ì€ vitalsë„ ë°›ìŒ\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            for i in range(imgs.size(0)):\n",
    "                # ì¡°ê±´: ì‹¤ì œ í™˜ìì´ê³ (1), ëª¨ë¸ ì˜ˆì¸¡ í™•ë¥ ì´ 80% ì´ìƒì¸ ê²½ìš°\n",
    "                if labels[i, target_idx] == 1 and probs[i, target_idx] > 0.8:\n",
    "\n",
    "                    # -----------------------------------------------------------\n",
    "                    # 1. ì›ë³¸ íŒŒì¼ ê²½ë¡œ ì°¾ê¸° (DataFrame ì´ìš©)\n",
    "                    # -----------------------------------------------------------\n",
    "                    # current_idx ê³„ì‚° ë¡œì§ ë³€ê²½: global_idxëŠ” ë°°ì¹˜ ì‹œì‘ ì¸ë±ìŠ¤, iëŠ” ë°°ì¹˜ ë‚´ ì¸ë±ìŠ¤\n",
    "                    # test_loaderì˜ shuffleì´ Falseì´ë¯€ë¡œ, df ì¸ë±ìŠ¤ì™€ global_idx + iê°€ ì¼ì¹˜í•´ì•¼ í•¨\n",
    "                    row = dataframe.iloc[global_idx + i]\n",
    "                    original_file_path = os.path.join(img_root_path, str(row['path']))\n",
    "\n",
    "                    # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ (ê³ í™”ì§ˆ)\n",
    "                    if not os.path.exists(original_file_path):\n",
    "                        print(f\"âš ï¸ ì›ë³¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {original_file_path}\")\n",
    "                        continue\n",
    "\n",
    "                    # cv2ë¡œ ê³ í™”ì§ˆ ì½ê¸° (BGR)\n",
    "                    src_img = cv2.imread(original_file_path)\n",
    "                    if src_img is None:\n",
    "                        print(f\"âš ï¸ ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŒ: {original_file_path}\")\n",
    "                        continue\n",
    "\n",
    "                    # ì‹œê°í™”ë¥¼ ìœ„í•´ RGBë¡œ ë³€í™˜\n",
    "                    src_img_rgb = cv2.cvtColor(src_img, cv2.COLOR_BGR2RGB)\n",
    "                    h, w, _ = src_img.shape # ì›ë³¸ í•´ìƒë„ (ì˜ˆ: 2500x2000 ë“±)\n",
    "\n",
    "                    print(f\"âœ… ë°œê²¬! Index: {global_idx + i}\")\n",
    "                    print(f\"   - íŒŒì¼ ê²½ë¡œ: {original_file_path}\")\n",
    "                    print(f\"   - ì›ë³¸ í•´ìƒë„: {w} x {h}, ì˜ˆì¸¡í™•ë¥ : {probs[i, target_idx]:.4f}\")\n",
    "\n",
    "                    # -----------------------------------------------------------\n",
    "                    # 2. íˆíŠ¸ë§µ ìƒì„± (7x7 -> ì›ë³¸ í¬ê¸°ë¡œ í™•ëŒ€)\n",
    "                    # -----------------------------------------------------------\n",
    "                    # Fusion ëª¨ë¸ì˜ attn_map ì‚¬ìš©\n",
    "                    cam_small = attn_maps[i].cpu().numpy() # (7, 7) í˜•íƒœ\n",
    "\n",
    "                    # ì •ê·œí™” (0~1)\n",
    "                    cam_norm = (cam_small - cam_small.min()) / (cam_small.max() - cam_small.min() + 1e-8)\n",
    "\n",
    "                    # ì›ë³¸ í¬ê¸°(w, h)ë¡œ í™•ëŒ€ (ì´ê²Œ í•µì‹¬!)\n",
    "                    cam_resized = cv2.resize(cam_norm, (w, h))\n",
    "\n",
    "                    # ì»¬ëŸ¬ë§µ ì ìš© (0~255 uint8 ë³€í™˜ í›„ ì ìš©) - JET ì»¬ëŸ¬ë§µì´ ë” ëª…í™•í•  ìˆ˜ ìˆìŒ\n",
    "                    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "\n",
    "                    # -----------------------------------------------------------\n",
    "                    # 3. ì›ë³¸ê³¼ í•©ì¹˜ê¸°\n",
    "                    # -----------------------------------------------------------\n",
    "                    # ì›ë³¸(src_img)ì— íˆíŠ¸ë§µì„ 50:50ìœ¼ë¡œ ì„ê¸°\n",
    "                    overlay = cv2.addWeighted(src_img, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "                    # -----------------------------------------------------------\n",
    "                    # 4. ì €ì¥ ë° ì¶œë ¥\n",
    "                    # -----------------------------------------------------------\n",
    "                    # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ì €ì¥\n",
    "                    save_name_overlay = f\"{save_dir}HQ_Fusion_Overlay_{target_disease}_{global_idx + i}.jpg\"\n",
    "                    cv2.imwrite(save_name_overlay, overlay)\n",
    "                    print(f\"ğŸ’¾ ê³ í™”ì§ˆ ì˜¤ë²„ë ˆì´ ì €ì¥ ì™„ë£Œ: {save_name_overlay}\")\n",
    "\n",
    "                    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥\n",
    "                    save_name_original = f\"{save_dir}HQ_Original_Image_{target_disease}_{global_idx + i}.jpg\"\n",
    "                    cv2.imwrite(save_name_original, src_img)\n",
    "                    print(f\"ğŸ’¾ ê³ í™”ì§ˆ ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_name_original}\")\n",
    "\n",
    "                    # ë…¸íŠ¸ë¶ ìƒì—ì„œ í™•ì¸ìš© (ì‘ê²Œ ì¶œë ¥)\n",
    "                    plt.figure(figsize=(10, 5))\n",
    "                    plt.subplot(1, 2, 1)\n",
    "                    plt.imshow(src_img_rgb)\n",
    "                    plt.title(\"Original High-Res\")\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "                    plt.title(f\"Fusion Model Heatmap\\n(Prob: {probs[i, target_idx]:.2f})\")\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "\n",
    "                    found_count += 1\n",
    "                    if found_count >= num_samples:\n",
    "                        return # ì›í•˜ëŠ” ìƒ˜í”Œ ìˆ˜ë§Œí¼ ì°¾ìœ¼ë©´ ì¢…ë£Œ\n",
    "            global_idx += imgs.size(0)\n",
    "\n",
    "# ì‹¤í–‰ (Image Only ëª¨ë¸ ì‚¬ìš©) -> Fusion ëª¨ë¸ë¡œ ë³€ê²½, 10ê°œ ìƒ˜í”Œ ì¶”ì¶œ\n",
    "# test_dfëŠ” 03ë²ˆ íŒŒì¼ ìƒë‹¨ì—ì„œ ë¡œë“œëœ ë°ì´í„°í”„ë ˆì„ì…ë‹ˆë‹¤.\n",
    "save_original_resolution_heatmap(model, test_loader, test_df, target_disease='Pneumonia', num_samples=10)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
